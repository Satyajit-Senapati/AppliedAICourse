{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yF1RvLfD8xMU"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRIhhiuQb82D"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq_hLyJh8xMc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "bnKoDrFqcAz5",
    "outputId": "8c9d4d3b-35e6-4357-be95-f48d3e7c8927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjwm7MXDcNsY"
   },
   "outputs": [],
   "source": [
    "dir_path=\"/content/drive/My Drive/Colab Notebooks/AppliedAI/HumanActivityRecognition/HAR/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqXcdZC68xMi"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJUJ8Xe_8xMq"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEtG4OvM8xMs"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDGeolif8xMx"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kV2JCazf8xM1"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'{dir_path}UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Yaytx9X_f04M",
    "outputId": "de3de793-7891-4d4f-94ff-a9fa9ca26697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/AppliedAI/HumanActivityRecognition/HAR/\n"
     ]
    }
   ],
   "source": [
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_Aunax08xM7"
   },
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'{dir_path}UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    # return pd.get_dummies(y).as_matrix()\n",
    "    return pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUfxWceW8xM_"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3OxkmSG58xNE",
    "outputId": "543c7884-9af6-4300-d416-f8b9428431a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPJELFsG8xNJ"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-W94-O88xNP"
   },
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tIWkuxK8xNW"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D,InputLayer,TimeDistributed,\\\n",
    "                          ConvLSTM2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVeuf-fB8xNa"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCaL6Yp88xNe"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "hCuQcIiM8xNk",
    "outputId": "13df71a4-a42a-4dbd-f6e8-eb44eacf55ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "rMbE3mbEA56Q",
    "outputId": "4569edd1-f482-47ce-f141-9adc6b5c6f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n",
      "(2947, 128, 9)\n",
      "(7352, 6)\n",
      "(2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "2ay_UqP28xNp",
    "outputId": "8e450545-e3cc-40be-f71f-788cae7e2042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JR8dktaL8xNy"
   },
   "outputs": [],
   "source": [
    "#container to hold all the parameters and results\n",
    "d = {\n",
    "        \"layers\"    : [],\n",
    "        \"n_hidden\"  : [],\n",
    "        \"dropout\"  : [],\n",
    "        \"parameters_trained\" : [],\n",
    "        \"train_acc\" : [],\n",
    "        \"test_acc\" : []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J26VMCSL8xN3"
   },
   "outputs": [],
   "source": [
    "def get_trainable_parameters(model):\n",
    "    trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    return trainable_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z97bR-dC8xN7"
   },
   "source": [
    "### Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2XF7Cpi8xN9"
   },
   "outputs": [],
   "source": [
    "def define_compile_model(n_hidden=[32],layer=1,dropout=[0.5]):\n",
    "    assert(len(n_hidden)==layer)\n",
    "    global timesteps,input_dim,n_classes,d\n",
    "    ret_seq = True if layer > 1 else False\n",
    "    d[\"layers\"].append(layer)\n",
    "    d[\"n_hidden\"].append(n_hidden)\n",
    "    d[\"dropout\"].append(dropout)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden[0],input_shape=(timesteps, input_dim),\n",
    "                   return_sequences=ret_seq))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout[0]))\n",
    "    for i in range(1,layer):\n",
    "        if i==layer-1:\n",
    "            ret_seq = False\n",
    "        model.add(LSTM(n_hidden[i],return_sequences=ret_seq))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout[i]))\n",
    "    model.add(Dense(n_classes,activation='sigmoid'))\n",
    "    model.summary()\n",
    "    # Compiling the model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])    # also tried adam\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "eYP4de6jER6B",
    "outputId": "8ec6d1f7-2fd8-4b9e-d878-cf5c573934fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
    "# Trying out different custom models\n",
    "\n",
    "# Model 1 : LSTM \n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps,input_dim),return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "livAqrDaqzo0"
   },
   "outputs": [],
   "source": [
    "# Model 2: CNN-LSTM\n",
    "\n",
    "n_steps, n_length = 4, 32\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, n_length, input_dim))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, n_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jU5tqlkFrc68"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, \n",
    "                  activation='relu'), input_shape=(None,n_length,input_dim)))\n",
    "model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3,\n",
    "                  activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhCbapbdwkw2"
   },
   "outputs": [],
   "source": [
    "# Model 3: ConvLSTM2D\n",
    "\n",
    "timesteps, input_dim, n_classes = X_train.shape[1], X_train.shape[2],\\\n",
    "                                  Y_train.shape[1]\n",
    "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "n_steps, n_length = 4, 32\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, input_dim))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, 1, n_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NoPSHN1wxXr"
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), \n",
    "                     activation='relu', \n",
    "                     input_shape=(n_steps, 1, n_length, input_dim)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "O8SzrN6yBuHs",
    "outputId": "c4fc2608-5c4e-4630-9f95-1d8bbdc5e470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_11 (TimeDis (None, None, 30, 64)      1792      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, None, 28, 32)      6176      \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, None, 28, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, None, 14, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, None, 448)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               219600    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 238,274\n",
      "Trainable params: 238,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWjkua078xOC"
   },
   "source": [
    "### fit  and predict model .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcWltszm8xOG"
   },
   "outputs": [],
   "source": [
    "def fit_model(X_train,y_train,batch_size,X_test,y_test,epochs,model):\n",
    "    global d\n",
    "    # Training the modela\n",
    "    model.fit(X_train,Y_train,batch_size=batch_size,\n",
    "              validation_data=(X_test, Y_test),epochs=epochs)\n",
    "    d[\"parameters_trained\"].append(get_trainable_parameters(model))\n",
    "    d[\"train_acc\"].append(model.history.history['acc'][-1])\n",
    "    # Confusion Matrix\n",
    "    print(confusion_matrix(Y_test, model.predict(X_test)))\n",
    "    return model\n",
    "\n",
    "def predict_model(X_test,y_test):\n",
    "    #evaluate the model :: socre[1] contains the accuracy for the given data ...\n",
    "    score = model.evaluate(X_test,Y_test)\n",
    "    d[\"test_acc\"].append(score[1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kllnb33w8xOR"
   },
   "source": [
    "### LSTM with layer = 1 , n_hidden = 32 and dropout = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "jyX55ZlwlXSI",
    "outputId": "fda7ffac-4521-4960-a4b7-5b61ccf2506a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128, 32)           8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 22,598\n",
      "Trainable params: 22,406\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = define_compile_model(n_hidden=[32,32,32],layer=3,\n",
    "                             dropout=[0.2,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o4U8efSt8xOW",
    "outputId": "d2f8bce7-a39b-4e0d-a708-7765be4414e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.4835 - acc: 0.8032 - val_loss: 0.5491 - val_acc: 0.8310\n",
      "Epoch 2/15\n",
      "7352/7352 [==============================] - 5s 626us/step - loss: 0.1771 - acc: 0.9338 - val_loss: 0.4791 - val_acc: 0.8500\n",
      "Epoch 3/15\n",
      "7352/7352 [==============================] - 5s 629us/step - loss: 0.1387 - acc: 0.9441 - val_loss: 0.3689 - val_acc: 0.8945\n",
      "Epoch 4/15\n",
      "7352/7352 [==============================] - 5s 643us/step - loss: 0.1294 - acc: 0.9472 - val_loss: 0.6042 - val_acc: 0.8551\n",
      "Epoch 5/15\n",
      "7352/7352 [==============================] - 5s 638us/step - loss: 0.1340 - acc: 0.9506 - val_loss: 0.4288 - val_acc: 0.8948\n",
      "Epoch 6/15\n",
      "7352/7352 [==============================] - 5s 633us/step - loss: 0.1163 - acc: 0.9508 - val_loss: 0.4495 - val_acc: 0.8877\n",
      "Epoch 7/15\n",
      "7352/7352 [==============================] - 5s 635us/step - loss: 0.1135 - acc: 0.9525 - val_loss: 0.4045 - val_acc: 0.8924\n",
      "Epoch 8/15\n",
      "7352/7352 [==============================] - 5s 628us/step - loss: 0.1151 - acc: 0.9514 - val_loss: 0.4384 - val_acc: 0.8928\n",
      "Epoch 9/15\n",
      "7352/7352 [==============================] - 5s 640us/step - loss: 0.1090 - acc: 0.9520 - val_loss: 0.4849 - val_acc: 0.8985\n",
      "Epoch 10/15\n",
      "7352/7352 [==============================] - 5s 649us/step - loss: 0.0986 - acc: 0.9563 - val_loss: 0.4449 - val_acc: 0.9046\n",
      "Epoch 11/15\n",
      "7352/7352 [==============================] - 5s 633us/step - loss: 0.1029 - acc: 0.9570 - val_loss: 0.5560 - val_acc: 0.8768\n",
      "Epoch 12/15\n",
      "7352/7352 [==============================] - 5s 640us/step - loss: 0.1087 - acc: 0.9548 - val_loss: 0.3356 - val_acc: 0.9080\n",
      "Epoch 13/15\n",
      "7352/7352 [==============================] - 5s 645us/step - loss: 0.0956 - acc: 0.9567 - val_loss: 0.5069 - val_acc: 0.9013\n",
      "Epoch 14/15\n",
      "7352/7352 [==============================] - 5s 646us/step - loss: 0.1087 - acc: 0.9548 - val_loss: 0.5025 - val_acc: 0.8873\n",
      "Epoch 15/15\n",
      "7352/7352 [==============================] - 5s 643us/step - loss: 0.1041 - acc: 0.9550 - val_loss: 0.4978 - val_acc: 0.9013\n",
      "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
      "True                                 ...                                      \n",
      "LAYING                 510        0  ...                   0                 1\n",
      "SITTING                  0      412  ...                   0                 7\n",
      "STANDING                 0       89  ...                   0                 0\n",
      "WALKING                  0        0  ...                  35                 7\n",
      "WALKING_DOWNSTAIRS       0        0  ...                 401                 7\n",
      "WALKING_UPSTAIRS         0        0  ...                  28               436\n",
      "\n",
      "[6 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(X_train,Y_train,batch_size,X_test,Y_test,15,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "R98c-UDI8xOb",
    "outputId": "c8c4a03d-ba23-4a27-f116-2f11684ca587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 87us/step\n"
     ]
    }
   ],
   "source": [
    "model = predict_model(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbTBKOLR8xOh"
   },
   "source": [
    "### printing d value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "76Wv8dhSaEGL",
    "outputId": "a4776343-bbed-4bdd-ca9b-e4acbecb828b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [], 'n_hidden': [], 'dropout': [], 'parameters_trained': [302982, 302982], 'train_acc': [0.9606909684439608, 0.9639553862894451], 'test_acc': [0.9104173736002714, 0.8730912792670512]}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rD7NEVyu8xOj",
    "outputId": "0d7e47f2-e94f-46a3-a8b9-c9be2ac8ba73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [], 'n_hidden': [], 'dropout': [], 'parameters_trained': [249026, 238274, 238274], 'train_acc': [0.9560663764961915, 0.9575625680087051, 0.9672198041349293], 'test_acc': [0.9121140142517815, 0.9243298269426535, 0.8598574821852731]}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKxmOEes8xOp"
   },
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwpalTLj8xOr",
    "outputId": "c49f3a02-7427-4be9-dd8d-e6ebeee983f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+--------------------+--------------------+--------------------+\n",
      "| layers | n_hidden |     dropout     | parameters_trained |     train_acc      |      test_acc      |\n",
      "+--------+----------+-----------------+--------------------+--------------------+--------------------+\n",
      "|   1    |    32    |      [0.5]      |        5574        | 0.9434167573449401 | 0.8842891075670173 |\n",
      "|   2    |    32    |    [0.5, 0.5]   |       13894        | 0.9473612622415669 | 0.8934509670851714 |\n",
      "|   3    |    64    | [0.3, 0.3, 0.3] |       85382        | 0.9533460282916213 | 0.9131319986426875 |\n",
      "+--------+----------+-----------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# hyper paratemer tunning\n",
    "# hidden units , dropout, lstm layers (but be careful that it will not overfit) (use different dropout rate .. )\n",
    "# use pretty table to conclude epochs can also be changed ..\n",
    "# pretty table columns - layers  , n_hidden, dropout used for each layer, train_Acc, test,Acc\n",
    "####################################\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"layers\", \"n_hidden\", \"dropout\", \"parameters_trained\",\"train_acc\",\"test_acc\"]\n",
    "for i in range(len(d[\"layers\"])):\n",
    "    x.add_row([d[\"layers\"][i],d[\"n_hidden\"][i],d[\"dropout\"][i],d[\"parameters_trained\"][i],d[\"train_acc\"][i],d[\"test_acc\"][i]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "C72gnyW-FX63",
    "outputId": "29e6eddc-29cc-4ca2-c6aa-ec8c380b74fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "| layers |     n_hidden     |       dropout        | parameters_trained |     train_acc      |      test_acc      |\n",
      "+--------+------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "|   1    |       [32]       |        [0.5]         |        5574        | 0.9434167573449401 | 0.8842891075670173 |\n",
      "|   1    |       [64]       |        [0.5]         |       19462        | 0.9480413492927094 | 0.8842891075670173 |\n",
      "|   1    |       [64]       |        [0.3]         |       19462        | 0.9500816104461371 | 0.9267051238547676 |\n",
      "|   1    |      [128]       |        [0.5]         |       71686        | 0.6228237214363439 | 0.168306752629793  |\n",
      "|   1    |      [128]       |        [0.5]         |       71686        | 0.9465451577801959 | 0.9280624363759755 |\n",
      "|   2    |     [32, 32]     |      [0.4, 0.3]      |       14022        | 0.9506256800870512 | 0.9287410926365796 |\n",
      "|   1    |      [256]       |        [0.5]         |       274438       | 0.9396082698585418 | 0.8992195453003053 |\n",
      "|   2    |     [64, 32]     |      [0.5, 0.4]      |       31750        | 0.9476332970620239 | 0.9124533423820834 |\n",
      "|   2    |     [64, 64]     |      [0.5, 0.5]      |       52614        | 0.9426006528835691 | 0.9267051238547676 |\n",
      "|   3    |   [32, 32, 32]   |   [0.5, 0.4, 0.3]    |       22406        | 0.9472252448313384 | 0.9178825924669155 |\n",
      "|   3    |   [64, 32, 16]   |   [0.5, 0.3, 0.1]    |       34822        | 0.9430087051142546 | 0.9243298269426535 |\n",
      "|   4    | [32, 32, 32, 32] | [0.4, 0.4, 0.4, 0.4] |       30790        | 0.9367519042437432 | 0.8948082796063793 |\n",
      "+--------+------------------+----------------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"layers\", \"n_hidden\", \"dropout\", \"parameters_trained\",\"train_acc\",\"test_acc\"]\n",
    "for i in range(len(d[\"layers\"])):\n",
    "    x.add_row([d[\"layers\"][i],d[\"n_hidden\"][i],d[\"dropout\"][i],d[\"parameters_trained\"][i],d[\"train_acc\"][i],d[\"test_acc\"][i]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "fXA1kjyBnJgy",
    "outputId": "e6b9bef4-7337-414f-a1a0-a4444b01618c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-----------------+--------------------+--------------------+--------------------+\n",
      "| layers |   n_hidden   |     dropout     | parameters_trained |     train_acc      |      test_acc      |\n",
      "+--------+--------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|   3    | [32, 32, 32] | [0.2, 0.2, 0.2] |       22406        | 0.9413764961915125 | 0.8988802171700034 |\n",
      "+--------+--------------+-----------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"layers\", \"n_hidden\", \"dropout\", \"parameters_trained\",\"train_acc\",\"test_acc\"]\n",
    "for i in range(len(d[\"layers\"])):\n",
    "    x.add_row([d[\"layers\"][i],d[\"n_hidden\"][i],d[\"dropout\"][i],d[\"parameters_trained\"][i],d[\"train_acc\"][i],d[\"test_acc\"][i]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhX6Ypo5GXCX"
   },
   "outputs": [],
   "source": [
    "table = PrettyTable(['layers','n_hidden','dropout','parameters_trained',\n",
    "                     'train_acc','test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc685lXHF8hv"
   },
   "outputs": [],
   "source": [
    "table.add_row([4,[100,100,6],[0.5,0.5],54706,0.9163492927094669,0.9066847641669494])\n",
    "table.add_row([3,[64,100,6],[0.5],249026,0.9560663764961915,0.9121140142517815])\n",
    "table.add_row([7,[64,32,100,100,6],[0.5,0.5],238274,0.9572198041349293,0.9298574821852731])\n",
    "table.add_row([7,[64,32,100,100,6],[0.5,0.5],238274,0.9675625680087051,0.9443298269426535])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "HlTB2LXvHAaz",
    "outputId": "d449cb87-9e1f-479d-da2b-f96946df3f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+------------+--------------------+--------------------+--------------------+\n",
      "| layers |        n_hidden       |  dropout   | parameters_trained |     train_acc      |      test_acc      |\n",
      "+--------+-----------------------+------------+--------------------+--------------------+--------------------+\n",
      "|   4    |     [100, 100, 6]     | [0.5, 0.5] |       54706        | 0.9163492927094669 | 0.9066847641669494 |\n",
      "|   3    |      [64, 100, 6]     |   [0.5]    |       249026       | 0.9560663764961915 | 0.9121140142517815 |\n",
      "|   7    | [64, 32, 100, 100, 6] | [0.5, 0.5] |       238274       | 0.9572198041349294 | 0.9298574821852731 |\n",
      "|   7    | [64, 32, 100, 100, 6] | [0.5, 0.5] |       238274       | 0.9675625680087051 | 0.9443298269426535 |\n",
      "+--------+-----------------------+------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDQ0CZytLiA3"
   },
   "outputs": [],
   "source": [
    "# Conclusions\n",
    "\n",
    "# We clearly see that the model performs fairly well on shallow LSTM layers\n",
    "# but as we increase the depth of the model architecture it suffers overfitting\n",
    "\n",
    "# Also, we experimented by adding large values of dropouts, and reducing the\n",
    "# number of training epochs but still the deep networks are not gettings any\n",
    "# better substantially\n",
    "\n",
    "# The best model having two LSTM layers each having 32 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igmeMHxLGc0d"
   },
   "outputs": [],
   "source": [
    "# At last we experimented with 2 other kinds of custome models instead of \n",
    "# vanilla LSTMS's. They were CNN-LSTM and ConvLSTM. We were able to achieve our\n",
    "# target accuracy of >94% using the CNN-LSTM model after palying around with \n",
    "# the hyperparams and number of epochs to avoid overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwVZMBrWSPQl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhT9k74PSStb"
   },
   "outputs": [],
   "source": [
    "# Trying out a completely new Github implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9H5O19y_Gji"
   },
   "outputs": [],
   "source": [
    "# Using code directly from :\n",
    "# https://github.com/heeryoncho/sensors2018cnnhar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyxyBb3kSWer"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdbV-I2g9V0y"
   },
   "outputs": [],
   "source": [
    "dir_path = dir_path+'UCI_HAR_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Jzs43dJ49VHX",
    "outputId": "25199131-8910-4285-a2b9-f35d7f90b39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/AppliedAI/HumanActivityRecognition/HAR/UCI_HAR_Dataset/\n"
     ]
    }
   ],
   "source": [
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpTE7aoF9KYU"
   },
   "outputs": [],
   "source": [
    "def load_x(train_or_test):\n",
    "    global dir_path\n",
    "    if train_or_test is \"train\":\n",
    "        x_path = dir_path + 'train/X_train.txt'\n",
    "    elif train_or_test is \"test\":\n",
    "        x_path = dir_path + 'test/X_test.txt'\n",
    "\n",
    "    with open(x_path) as f:\n",
    "        container = f.readlines()\n",
    "\n",
    "    result = []\n",
    "    for line in container:\n",
    "        tmp1 = line.strip()\n",
    "        tmp2 = tmp1.replace('  ', ' ')     # removes inconsistent blank spaces\n",
    "        tmp_ary = list(map(float, tmp2.split(' ')))\n",
    "        result.append(tmp_ary)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1iQLMe01YaU_"
   },
   "outputs": [],
   "source": [
    "def load_y(train_or_test):\n",
    "    global dir_path\n",
    "    if train_or_test is \"train\":\n",
    "        y_path = dir_path + 'train/y_train.txt'\n",
    "    elif train_or_test is \"test\":\n",
    "        y_path = dir_path + 'test/y_test.txt'\n",
    "\n",
    "    with open(y_path) as f:\n",
    "        container = f.readlines()\n",
    "\n",
    "    result = []\n",
    "    for line in container:\n",
    "        num_str = line.strip()\n",
    "        result.append(int(num_str))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hxpu1AUHYaIb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shjw3djEFu8f"
   },
   "outputs": [],
   "source": [
    "X_train_all = load_x(\"train\")\n",
    "y_train_all = load_y(\"train\")\n",
    "\n",
    "X_test_all = load_x(\"test\")\n",
    "y_test_all = load_y(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "TqWq9xgKRuqy",
    "outputId": "ef84b323-34ec-40d8-bef8-1a2786a87031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++ DATA STATISTICS +++\n",
      "\n",
      "train_dynamic shape:  (3285, 561)\n",
      "test_dynamic shape:  (1387, 561)\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Only dynamic HAR data are selected\n",
    "# --------------------------------------\n",
    "\n",
    "# Select dynamic HAR train data\n",
    "\n",
    "dynamic_1 = np.where(y_train_all == 1)[0]\n",
    "dynamic_2 = np.where(y_train_all == 2)[0]\n",
    "dynamic_3 = np.where(y_train_all == 3)[0]\n",
    "dynamic = np.concatenate([dynamic_1, dynamic_2, dynamic_3])\n",
    "\n",
    "X_train = X_train_all[dynamic]\n",
    "y_train = y_train_all[dynamic]\n",
    "\n",
    "# Convert (1, 2, 3) labels to (0, 1, 2)\n",
    "y_train  = y_train - 1\n",
    "\n",
    "print(\"\\n+++ DATA STATISTICS +++\\n\")\n",
    "print(\"train_dynamic shape: \", X_train.shape)\n",
    "\n",
    "# Select dynamic HAR test data\n",
    "\n",
    "dynamic_1 = np.where(y_test_all == 1)[0]\n",
    "dynamic_2 = np.where(y_test_all == 2)[0]\n",
    "dynamic_3 = np.where(y_test_all == 3)[0]\n",
    "dynamic = np.concatenate([dynamic_1, dynamic_2, dynamic_3])\n",
    "\n",
    "X_test = X_test_all[dynamic]\n",
    "y_test = y_test_all[dynamic]\n",
    "\n",
    "# Convert (1, 2, 3) labels to (0, 1, 2)\n",
    "y_test  = y_test - 1\n",
    "\n",
    "print(\"test_dynamic shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "0kRJFKOBy4yd",
    "outputId": "881018e4-0f9d-4adb-9380-5550ec60dcb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/AppliedAI/HumanActivityRecognition/HAR/UCI_HAR_Dataset/'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "colab_type": "code",
    "id": "vf0Byhx7VT2E",
    "outputId": "54a34a27-3df9-4c73-ca98-20771aa97ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++ DYNAMIC MODEL ACCURACY (See Table 8 in paper) +++\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:350: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRAIN ACCURACY ------\n",
      "0.9863013698630136\n",
      "[[1223    3    0]\n",
      " [   4 1038   31]\n",
      " [   0    7  979]]\n",
      "------ TEST ACCURACY ------\n",
      "0.9798125450612833\n",
      "[[495   0   1]\n",
      " [  2 469   0]\n",
      " [  2  23 395]]\n"
     ]
    }
   ],
   "source": [
    "# Display dynamic model accuracy\n",
    "\n",
    "print(\"\\n+++ DYNAMIC MODEL ACCURACY (See Table 8 in paper) +++\\n\")\n",
    "\n",
    "model_path = dir_path+\"models/dynamic.hdf5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "pred_train = model.predict(np.expand_dims(X_train, axis=2), batch_size=32)\n",
    "print(\"------ TRAIN ACCURACY ------\")\n",
    "print(accuracy_score(y_train, np.argmax(pred_train, axis=1)))\n",
    "print(confusion_matrix(y_train, np.argmax(pred_train, axis=1)))\n",
    "\n",
    "pred_test = model.predict(np.expand_dims(X_test, axis=2), batch_size=32)\n",
    "print(\"------ TEST ACCURACY ------\")\n",
    "print(accuracy_score(y_test, np.argmax(pred_test, axis=1)))\n",
    "print(confusion_matrix(y_test, np.argmax(pred_test, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "colab_type": "code",
    "id": "dJfprZRpVEVx",
    "outputId": "6b8ec92a-d62f-4511-c8bd-5a7585ed6c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++ DATA STATISTICS +++\n",
      "\n",
      "train_static shape:  (4067, 561)\n",
      "test_static shape:  (1560, 561)\n",
      "\n",
      "+++ STATIC MODEL ACCURACY (See Table 8 in paper) +++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:350: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRAIN ACCURACY ------\n",
      "0.9923776739611507\n",
      "[[1275   11    0]\n",
      " [  20 1354    0]\n",
      " [   0    0 1407]]\n",
      "------ TEST ACCURACY ------\n",
      "0.966025641025641\n",
      "[[453  38   0]\n",
      " [ 14 518   0]\n",
      " [  1   0 536]]\n"
     ]
    }
   ],
   "source": [
    "static_1 = np.where(y_train_all == 4)[0]\n",
    "static_2 = np.where(y_train_all == 5)[0]\n",
    "static_3 = np.where(y_train_all == 6)[0]\n",
    "static = np.concatenate([static_1, static_2, static_3])\n",
    "\n",
    "X_train = X_train_all[static]\n",
    "y_train = y_train_all[static]\n",
    "\n",
    "# Convert (4, 5, 6) labels to (0, 1, 2)\n",
    "y_train  = y_train - 4\n",
    "\n",
    "print(\"\\n+++ DATA STATISTICS +++\\n\")\n",
    "print(\"train_static shape: \", X_train.shape)\n",
    "\n",
    "# Select static HAR test data\n",
    "\n",
    "static_1 = np.where(y_test_all == 4)[0]\n",
    "static_2 = np.where(y_test_all == 5)[0]\n",
    "static_3 = np.where(y_test_all == 6)[0]\n",
    "static = np.concatenate([static_1, static_2, static_3])\n",
    "\n",
    "X_test = X_test_all[static]\n",
    "y_test = y_test_all[static]\n",
    "\n",
    "# Convert (4, 5, 6) labels to (0, 1, 2)\n",
    "y_test  = y_test - 4\n",
    "\n",
    "print(\"test_static shape: \", X_test.shape)\n",
    "\n",
    "\n",
    "# Display static model accuracy\n",
    "\n",
    "print(\"\\n+++ STATIC MODEL ACCURACY (See Table 8 in paper) +++\\n\")\n",
    "\n",
    "model_path = dir_path+\"models/static.hdf5\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "pred_train = model.predict(np.expand_dims(X_train, axis=2), batch_size=32)\n",
    "print(\"------ TRAIN ACCURACY ------\")\n",
    "print(accuracy_score(y_train, np.argmax(pred_train, axis=1)))\n",
    "print(confusion_matrix(y_train, np.argmax(pred_train, axis=1)))\n",
    "\n",
    "pred_test = model.predict(np.expand_dims(X_test, axis=2), batch_size=32)\n",
    "print(\"------ TEST ACCURACY ------\")\n",
    "print(accuracy_score(y_test, np.argmax(pred_test, axis=1)))\n",
    "print(confusion_matrix(y_test, np.argmax(pred_test, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmOXL-m0ZH-5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_LSTM_done.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
