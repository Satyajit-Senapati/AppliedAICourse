{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4XAwG0QVzDU"
   },
   "source": [
    "## Assignment : 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uOH1kSNJvfp"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SM9Mz5lxULM2",
    "outputId": "987473b6-3f6f-4215-bcbd-783d323604c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Flatten, LSTM,\\\n",
    "                      Dropout, concatenate, Conv1D,BatchNormalization\n",
    "from tensorflow.keras import regularizers,initializers,optimizers,Model\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5qd8X1i9VzDY"
   },
   "source": [
    "<pre>\n",
    "1. Preprocess all the Data we have in DonorsChoose <a href='https://drive.google.com/drive/folders/1MIwK7BQMev8f5CbDDVNLPaFGB32pFN60'>Dataset</a> use train.csv\n",
    "2. Combine 4 essay's into one column named - 'preprocessed_essays'. \n",
    "3. After step 2 you have to train 3 types of models as discussed below. \n",
    "4. For all the model use <a href='https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics'>'auc'</a> as a metric. check <a href='https://datascience.stackexchange.com/a/20192'>this</a> for using auc as a metric \n",
    "5. You are free to choose any number of layers/hiddden units but you have to use same type of architectures shown below. \n",
    "6. You can use any one of the optimizers and choice of Learning rate and momentum, resources: <a href='http://cs231n.github.io/neural-networks-3/'>cs231n class notes</a>, <a href='https://www.youtube.com/watch?v=hd_KFJ5ktUc'>cs231n class video</a>. \n",
    "7. For all the model's use <a href='https://www.youtube.com/watch?v=2U6Jl7oqRkM'>TensorBoard</a> and plot the Metric value and Loss with epoch. While submitting, take a screenshot of plots and include those images in .ipynb notebook and PDF. \n",
    "8. Use Categorical Cross Entropy as Loss to minimize.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "_QiyE0T9YHxY",
    "outputId": "d38ac353-57e4-4fcd-bb51-16874949f7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fljI_7I2TdIw"
   },
   "outputs": [],
   "source": [
    "dir_path=\"/content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "nUiy_XPNFWq5",
    "outputId": "72afec23-8baf-4194-cb35-3d28109a41c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+\n",
      "| Model | Weighted Test AUC | Micro Test AUC |\n",
      "+-------+-------------------+----------------+\n",
      "+-------+-------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "table = PrettyTable(field_names=[\"Model\",\"Weighted Test AUC\",\"Micro Test AUC\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PG0WzOUNLWgQ"
   },
   "outputs": [],
   "source": [
    "with open(dir_path+'glove_vectors', 'rb') as f:\n",
    "    glove = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOg9Os30r8LA"
   },
   "outputs": [],
   "source": [
    "# _df_Resource = pd.read_csv(dir_path+'resources.csv')\n",
    "# _df_Resource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWoUSRAXslHn"
   },
   "outputs": [],
   "source": [
    "# _df_train = pd.read_csv(dir_path+'train_data.csv')\n",
    "# _df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "colab_type": "code",
    "id": "YVSTIN_wUMp6",
    "outputId": "0ccb3e66-9272-4359-e64a-e85829fe1ccb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_state</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_subcategories</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>math_science</td>\n",
       "      <td>appliedsciences health_lifescience</td>\n",
       "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
       "      <td>725.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ut</td>\n",
       "      <td>ms</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>specialneeds</td>\n",
       "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
       "      <td>213.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>having class 24 students comes diverse learner...</td>\n",
       "      <td>329.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ga</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>appliedlearning</td>\n",
       "      <td>earlydevelopment</td>\n",
       "      <td>i recently read article giving students choice...</td>\n",
       "      <td>481.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>mrs</td>\n",
       "      <td>grades_3_5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>literacy</td>\n",
       "      <td>my students crave challenge eat obstacles brea...</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  school_state  ...   price\n",
       "0           ca  ...  725.05\n",
       "1           ut  ...  213.03\n",
       "2           ca  ...  329.00\n",
       "3           ga  ...  481.04\n",
       "4           wa  ...   17.74\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df=pd.read_csv(dir_path+'preprocessed_data.csv')\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "-jwVfP3UVOTD",
    "outputId": "2ad23d17-d829-49c5-f8dc-1e089c727b70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109248, 9)\n",
      "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
      "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
      "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_df.shape)\n",
    "print(preprocessed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ob9MlCMoGabi"
   },
   "outputs": [],
   "source": [
    "project_approved = preprocessed_df.project_is_approved\n",
    "preprocessed_df.drop(columns='project_is_approved', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEoQf4lVVOQD"
   },
   "outputs": [],
   "source": [
    "# this is random splitting into train and test set\n",
    "dfX_train, dfX_test, y_train, y_test = train_test_split(preprocessed_df,\n",
    "                              project_approved,test_size=0.30, random_state = 0,\n",
    "                              stratify = project_approved)\n",
    "dfX_cv, dfX_test, y_cv, y_test = train_test_split(dfX_test,\n",
    "                              y_test,test_size=0.50, random_state = 0,\n",
    "                              stratify = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PP9kjKc6QIhe"
   },
   "outputs": [],
   "source": [
    "# For column school state\n",
    "\n",
    "tokenizer_schoolState = Tokenizer(oov_token='<oov>')\n",
    "tokenizer_schoolState.fit_on_texts(dfX_train.school_state.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgquarZcBRrw"
   },
   "outputs": [],
   "source": [
    "max_schoolState_length = dfX_train.school_state.apply(lambda x : len(x.split(' '))).max()\n",
    "tokenised_schoolState_train = tokenizer_schoolState.texts_to_sequences(dfX_train.school_state)\n",
    "tokenised_schoolState_test = tokenizer_schoolState.texts_to_sequences(dfX_test.school_state)\n",
    "tokenised_schoolState_cv = tokenizer_schoolState.texts_to_sequences(dfX_cv.school_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waXChYoNrxyu"
   },
   "outputs": [],
   "source": [
    "X_train_schoolState = pad_sequences(tokenised_schoolState_train, \n",
    "                                    maxlen=max_schoolState_length)\n",
    "X_test_schoolState = pad_sequences(tokenised_schoolState_test,\n",
    "                                    maxlen=max_schoolState_length)\n",
    "X_cv_schoolState = pad_sequences(tokenised_schoolState_cv,\n",
    "                                    maxlen=max_schoolState_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5bFjl0xeGmJ"
   },
   "outputs": [],
   "source": [
    "# For column teacher_prefix\n",
    "\n",
    "tokenizer_teacherPrefix = Tokenizer(oov_token='<oov>')\n",
    "tokenizer_teacherPrefix.fit_on_texts(dfX_train.teacher_prefix.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DS6g0RnqqZB_"
   },
   "outputs": [],
   "source": [
    "max_teacherPrefix_length = dfX_train.teacher_prefix.apply(lambda x : len(x.split(' '))).max()\n",
    "tokenised_teacherPrefix_train = tokenizer_teacherPrefix.texts_to_sequences(dfX_train.teacher_prefix)\n",
    "tokenised_teacherPrefix_test = tokenizer_teacherPrefix.texts_to_sequences(dfX_test.teacher_prefix)\n",
    "tokenised_teacherPrefix_cv = tokenizer_teacherPrefix.texts_to_sequences(dfX_cv.teacher_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qE62QynAtPXL"
   },
   "outputs": [],
   "source": [
    "X_train_teacherPrefix = pad_sequences(tokenised_teacherPrefix_train, \n",
    "                                    maxlen=max_teacherPrefix_length)\n",
    "X_test_teacherPrefix = pad_sequences(tokenised_teacherPrefix_test,\n",
    "                                    maxlen=max_teacherPrefix_length)\n",
    "X_cv_teacherPrefix = pad_sequences(tokenised_teacherPrefix_cv,\n",
    "                                    maxlen=max_teacherPrefix_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjvgNEI8Enr7"
   },
   "outputs": [],
   "source": [
    "# For column project_grade_category\n",
    "\n",
    "tokenizer_pgCategory = Tokenizer(oov_token='<oov>',\n",
    "                        filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "tokenizer_pgCategory.fit_on_texts(dfX_train.project_grade_category.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdDxsuqEGmUY"
   },
   "outputs": [],
   "source": [
    "max_pgCategory_length = dfX_train.project_grade_category.apply(lambda x : len(x.split(' '))).max()\n",
    "tokenised_pgCategory_train = tokenizer_pgCategory.texts_to_sequences(dfX_train.project_grade_category)\n",
    "tokenised_pgCategory_test = tokenizer_pgCategory.texts_to_sequences(dfX_test.project_grade_category)\n",
    "tokenised_pgCategory_cv = tokenizer_pgCategory.texts_to_sequences(dfX_cv.project_grade_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-kb3dn-jvxbI"
   },
   "outputs": [],
   "source": [
    "X_train_pgCategory = pad_sequences(tokenised_pgCategory_train, \n",
    "                                    maxlen=max_pgCategory_length)\n",
    "X_test_pgCategory = pad_sequences(tokenised_pgCategory_test,\n",
    "                                    maxlen=max_pgCategory_length)\n",
    "X_cv_pgCategory = pad_sequences(tokenised_pgCategory_cv,\n",
    "                                    maxlen=max_pgCategory_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "M0UMBovMlRxY",
    "outputId": "2eea9c9f-89c4-4a34-f770-92aed646020c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<oov>',\n",
       " 2: 'grades_prek_2',\n",
       " 3: 'grades_3_5',\n",
       " 4: 'grades_6_8',\n",
       " 5: 'grades_9_12'}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_pgCategory.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oE2rbBJtGmRt"
   },
   "outputs": [],
   "source": [
    "# For column clean_categories\n",
    "\n",
    "tokenizer_cleanCategory = Tokenizer(oov_token='<oov>',\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "tokenizer_cleanCategory.fit_on_texts(dfX_train.clean_categories.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaP5H-lsK6Mm"
   },
   "outputs": [],
   "source": [
    "max_cleanCategory_length = dfX_train.clean_categories.apply(lambda x : len(x.split(' '))).max()\n",
    "tokenised_cleanCategory_train = tokenizer_cleanCategory.texts_to_sequences(dfX_train.clean_categories)\n",
    "tokenised_cleanCategory_test = tokenizer_cleanCategory.texts_to_sequences(dfX_test.clean_categories)\n",
    "tokenised_cleanCategory_cv = tokenizer_cleanCategory.texts_to_sequences(dfX_cv.clean_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1H04vnLfwV3Y"
   },
   "outputs": [],
   "source": [
    "X_train_cleanCategory = pad_sequences(tokenised_cleanCategory_train, \n",
    "                                    maxlen=max_cleanCategory_length)\n",
    "X_test_cleanCategory = pad_sequences(tokenised_cleanCategory_test,\n",
    "                                    maxlen=max_cleanCategory_length)\n",
    "X_cv_cleanCategory = pad_sequences(tokenised_cleanCategory_cv,\n",
    "                                    maxlen=max_cleanCategory_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HddJ2NfLNsU"
   },
   "outputs": [],
   "source": [
    "# For column clean_subcategories\n",
    "\n",
    "tokenizer_cleanSubCategory = Tokenizer(oov_token='<oov>',\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "tokenizer_cleanSubCategory.fit_on_texts(dfX_train.clean_subcategories.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meHTnmx6LNhj"
   },
   "outputs": [],
   "source": [
    "max_cleanSubCategory_length = dfX_train.clean_subcategories.apply(lambda x : len(x.split(' '))).max()\n",
    "tokenised_cleanSubCategory_train = tokenizer_cleanSubCategory.texts_to_sequences(dfX_train.clean_subcategories)\n",
    "tokenised_cleanSubCategory_test = tokenizer_cleanSubCategory.texts_to_sequences(dfX_test.clean_subcategories)\n",
    "tokenised_cleanSubCategory_cv = tokenizer_cleanSubCategory.texts_to_sequences(dfX_cv.clean_subcategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjRgPxU6wybs"
   },
   "outputs": [],
   "source": [
    "X_train_cleanSubCategory = pad_sequences(tokenised_cleanSubCategory_train, \n",
    "                                    maxlen=max_cleanSubCategory_length)\n",
    "X_test_cleanSubCategory = pad_sequences(tokenised_cleanSubCategory_test,\n",
    "                                    maxlen=max_cleanSubCategory_length)\n",
    "X_cv_cleanSubCategory = pad_sequences(tokenised_cleanSubCategory_cv,\n",
    "                                    maxlen=max_cleanSubCategory_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MnHSAZ-Wrt__"
   },
   "outputs": [],
   "source": [
    "# For column essay\n",
    "\n",
    "tokenizer_Essay = Tokenizer(oov_token='<oov>')\n",
    "tokenizer_Essay.fit_on_texts(dfX_train.essay.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7wr5X7MSRvu"
   },
   "outputs": [],
   "source": [
    "# we found the max_essay_length using max length of list of the tokens\n",
    "max_essay_length = 350\n",
    "tokenised_essay_train = tokenizer_Essay.texts_to_sequences(dfX_train.essay)\n",
    "tokenised_essay_test = tokenizer_Essay.texts_to_sequences(dfX_test.essay)\n",
    "tokenised_essay_cv = tokenizer_Essay.texts_to_sequences(dfX_cv.essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7toGtovQK90j"
   },
   "outputs": [],
   "source": [
    "X_train_essay = pad_sequences(tokenised_essay_train, maxlen=max_essay_length)\n",
    "X_test_essay = pad_sequences(tokenised_essay_test, maxlen=max_essay_length)\n",
    "X_cv_essay = pad_sequences(tokenised_essay_cv, maxlen=max_essay_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d05M5uUtNZyL"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 300     # glove vectors are 300 dims\n",
    "VOCAB_SIZE = len(list(tokenizer_Essay.word_counts.keys()))\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIMS))\n",
    "for word, i in tokenizer_Essay.word_index.items():\n",
    "    embedding_vector = glove.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "UyhDNvxzEvXE",
    "outputId": "4cf92721-9acd-462d-96b6-644051299493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
       "       'teacher_number_of_previously_posted_projects', 'clean_categories',\n",
       "       'clean_subcategories', 'essay', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vzx2Ng1VzDb"
   },
   "source": [
    "### Model-1\n",
    "\n",
    "Build and Train deep neural network as shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hygErqe0VzDc"
   },
   "source": [
    "<img src='https://i.imgur.com/w395Yk9.png'>\n",
    "ref: https://i.imgur.com/w395Yk9.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ov3jfUTVzDd"
   },
   "source": [
    "- __Input_seq_total_text_data__ --- You have to give Total text data columns. After this use the Embedding layer to get word vectors. Use given predefined glove word vectors, don't train any word vectors. After this use LSTM and get the LSTM output and Flatten that output. \n",
    "- __Input_school_state__ --- Give 'school_state' column as input to embedding layer and Train the Keras Embedding layer. \n",
    "- __Project_grade_category__  --- Give 'project_grade_category' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_categories__ --- Give 'input_clean_categories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_clean_subcategories' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_clean_subcategories__ --- Give 'input_teacher_prefix' column as input to embedding layer and Train the Keras Embedding layer.\n",
    "- __Input_remaining_teacher_number_of_previously_posted_projects._resource_summary_contains_numerical_digits._price._quantity__ ---concatenate remaining columns and add a Dense layer after that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ha4QAtMwVzDe"
   },
   "source": [
    "- For LSTM, you can choose your sequence padding methods on your own or you can train your LSTM without padding, there is no restriction on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJrjctoGVzDf"
   },
   "source": [
    "Below is an example of embedding layer for a categorical columns. In below code all are dummy values, we gave only for referance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz3zbr-mK5AJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# def auc( y_true, y_pred ):\n",
    "#     # This is for calculating the AUC Score\n",
    "#     # Added this code as sometimes the y_true comes to be of a single class\n",
    "#     # causing error\n",
    "#     # https://stackoverflow.com/questions/45139163/roc-auc-score-only-one-class-present-in-y-true\n",
    "\n",
    "#     score = 0.0\n",
    "#     if len(np.unique(y_true)) == 1: # bug in roc_auc_score\n",
    "#         score = tf.py_func(lambda y_true, y_pred : accuracy_score(y_true, \n",
    "#                                           y_pred).astype('float32'),\n",
    "#                         [y_true, y_pred],\n",
    "#                         'float32',\n",
    "#                         stateful=True,\n",
    "#                         name='sklearnAUC' )\n",
    "#     else:\n",
    "#         score = tf.py_func( lambda y_true, y_pred : roc_auc_score(y_true, y_pred, \n",
    "#                         average='weighted', sample_weight=None).astype('float32'),\n",
    "#                         [y_true, y_pred],\n",
    "#                         'float32',\n",
    "#                         stateful=True,\n",
    "#                         name='sklearnAUC' )\n",
    "        \n",
    "#     return score\n",
    "\n",
    "def auc_temp(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    return tf.py_function(auc_temp, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV0671QcVzDg"
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
    "# input_layer = Input(shape=(n,))\n",
    "# embedding = Embedding(no_1, no_2, input_length=n)(input_layer)\n",
    "# flatten = Flatten()(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "ueFzl0XWMA7h",
    "outputId": "7254b3b8-52ad-45e4-f3a2-922aac70605b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# school state imput\n",
    "school_state_inp = Input(shape=(max_schoolState_length,), dtype='int32',\n",
    "                         name='school_state_inp')\n",
    "embedded_school_state = Embedding(input_dim=len(tokenizer_schoolState.word_index.items()),   # 51\n",
    "                            output_dim=6,name='embedded_school_state')(school_state_inp)\n",
    "school_state_out = Flatten()(embedded_school_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9mvC53G9km3"
   },
   "outputs": [],
   "source": [
    "# teacher prefix\n",
    "teacher_Pref_inp = Input(shape=(max_teacherPrefix_length,),dtype='int32',\n",
    "                         name='teacher_Pref_inp')\n",
    "embedded_teacher_Pref = Embedding(input_dim=len(tokenizer_teacherPrefix.word_index.items()),\n",
    "                        output_dim=2,name='embedded_teacher_Pref')(teacher_Pref_inp)\n",
    "teacher_Pref_out = Flatten()(embedded_teacher_Pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpZpqdywHMCI"
   },
   "outputs": [],
   "source": [
    "# project grade category\n",
    "pgCategory_Inp = Input(shape=(max_pgCategory_length,),dtype='int32',\n",
    "                       name='pgCategory_Inp')\n",
    "embedded_pgCategory = Embedding(input_dim=len(tokenizer_pgCategory.word_index.items()),\n",
    "                        output_dim=2,name='embedded_pgCategory')(pgCategory_Inp)\n",
    "pgCategory_Out = Flatten()(embedded_pgCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovlrD1-LH90G"
   },
   "outputs": [],
   "source": [
    "# project clean_categories\n",
    "cleanCategory_Inp = Input(shape=(max_cleanCategory_length,),dtype='int32',\n",
    "                          name='cleanCategory_Inp')\n",
    "embedded_cleanCategory = Embedding(input_dim=len(tokenizer_cleanCategory.word_index.items()),\n",
    "                        output_dim=3,name='embedded_cleanCategory')(cleanCategory_Inp)\n",
    "cleanCategory_Out = Flatten()(embedded_cleanCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI-m1aIqIpLH"
   },
   "outputs": [],
   "source": [
    "# project clean_subcategories\n",
    "clean_subcategories_Inp = Input(shape=(max_cleanSubCategory_length,),dtype='int32',\n",
    "                                name='clean_subcategories_Inp')\n",
    "embedded_cleanSubCategory = Embedding(input_dim=len(tokenizer_cleanSubCategory.word_index.items()),\n",
    "                        output_dim=5,name='embedded_cleanSubCategory')(clean_subcategories_Inp)\n",
    "clean_subcategories_Out = Flatten()(embedded_cleanSubCategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMcyH1-DJu-6"
   },
   "outputs": [],
   "source": [
    "# essay\n",
    "essay_Inp = Input(shape=(max_essay_length,),dtype='int32',\n",
    "                  name='essay_Inp')\n",
    "embedded_Essay = Embedding(input_dim=len(tokenizer_Essay.word_index.items()),\n",
    "                        output_dim=300,name='embedded_Essay',\n",
    "                        weights=[embedding_matrix],\n",
    "                        trainable=False)(essay_Inp)\n",
    "essay_LSTM = LSTM(units=128, return_sequences=True)(embedded_Essay)\n",
    "essay_Out = Flatten()(essay_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "6EkjopN7-pIx",
    "outputId": "ea0b16a9-ce19-4a89-ea6a-52dffcc39980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# concatenating remaining columns teacher_number_of_previously_posted_projects \n",
    "# and price\n",
    "\n",
    "dfX_train['remaining_cols']=dfX_train[['teacher_number_of_previously_posted_projects',\n",
    "    'price']].apply(\n",
    "    lambda x : [x.teacher_number_of_previously_posted_projects, x.price],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umEOosoM-bGx"
   },
   "outputs": [],
   "source": [
    "dfX_test['remaining_cols']=dfX_test[['teacher_number_of_previously_posted_projects',\n",
    "    'price']].apply(\n",
    "    lambda x : [x.teacher_number_of_previously_posted_projects, x.price],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVk1j6t4GHq8"
   },
   "outputs": [],
   "source": [
    "dfX_cv['remaining_cols']=dfX_cv[['teacher_number_of_previously_posted_projects',\n",
    "    'price']].apply(\n",
    "    lambda x : [x.teacher_number_of_previously_posted_projects, x.price],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9eP8Vd-8cS8"
   },
   "outputs": [],
   "source": [
    "remaining_cols_Inp = Input(shape=(2,), dtype='float32', name='remaining_cols_Inp')\n",
    "dense_remaining = Dense(16,activation='relu',\n",
    "                        kernel_regularizer=regularizers.l2(0.001),\n",
    "                        kernel_initializer=initializers.he_normal())\n",
    "remaining_cols_Out = dense_remaining(remaining_cols_Inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDK364foHdJT"
   },
   "outputs": [],
   "source": [
    "# concatenating all the outputs\n",
    "\n",
    "concatenated_Outs = concatenate([school_state_out, teacher_Pref_out,\n",
    "                pgCategory_Out,cleanCategory_Out,clean_subcategories_Out,\n",
    "                essay_Out,remaining_cols_Out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdM4pFbuFrxk"
   },
   "outputs": [],
   "source": [
    "outPut = Dense(128,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(concatenated_Outs)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = Dense(64,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = BatchNormalization()(outPut)\n",
    "outPut = Dense(32,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = Dense(2, activation = 'softmax')(outPut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mXP9RzqOH4yW",
    "outputId": "a8bc3f8e-3682-4116-c0eb-d2297821e3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "essay_Inp (InputLayer)          [(None, 350)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "school_state_inp (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_Pref_inp (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pgCategory_Inp (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cleanCategory_Inp (InputLayer)  [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories_Inp (InputL [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedded_Essay (Embedding)      (None, 350, 300)     14799000    essay_Inp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedded_school_state (Embeddin (None, 1, 6)         312         school_state_inp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedded_teacher_Pref (Embeddin (None, 1, 2)         12          teacher_Pref_inp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedded_pgCategory (Embedding) (None, 1, 2)         10          pgCategory_Inp[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedded_cleanCategory (Embeddi (None, 3, 3)         30          cleanCategory_Inp[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedded_cleanSubCategory (Embe (None, 3, 5)         155         clean_subcategories_Inp[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 350, 128)     219648      embedded_Essay[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "remaining_cols_Inp (InputLayer) [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6)            0           embedded_school_state[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedded_teacher_Pref[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedded_pgCategory[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 9)            0           embedded_cleanCategory[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 15)           0           embedded_cleanSubCategory[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 44800)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           48          remaining_cols_Inp[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 44850)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          5740928     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            66          dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,770,801\n",
      "Trainable params: 5,971,673\n",
      "Non-trainable params: 14,799,128\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model with all the previously defined inputs\n",
    "model1 = Model([school_state_inp,teacher_Pref_inp,pgCategory_Inp,\n",
    "                cleanCategory_Inp,clean_subcategories_Inp,essay_Inp,\n",
    "                remaining_cols_Inp], outPut)\n",
    "model1.compile(loss='categorical_crossentropy', \n",
    "               optimizer=optimizers.Adam(lr=0.0006,decay = 1e-4),\n",
    "               metrics=[auc])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6p6VemeVH4kV",
    "outputId": "63e89dcf-e063-4794-9ba3-63b26e142601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 53531 samples, validate on 22942 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.59106, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 151s - loss: 0.7298 - auc: 0.5241 - val_loss: 0.5772 - val_auc: 0.5911\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.59106 to 0.60180, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 151s - loss: 0.5841 - auc: 0.5468 - val_loss: 0.5339 - val_auc: 0.6018\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.60180\n",
      "53531/53531 - 151s - loss: 0.5439 - auc: 0.5456 - val_loss: 0.5224 - val_auc: 0.5959\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.60180 to 0.61066, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 149s - loss: 0.5168 - auc: 0.5606 - val_loss: 0.5040 - val_auc: 0.6107\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.61066\n",
      "53531/53531 - 146s - loss: 0.4972 - auc: 0.5688 - val_loss: 0.4876 - val_auc: 0.6026\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.61066\n",
      "53531/53531 - 146s - loss: 0.4843 - auc: 0.5767 - val_loss: 0.4798 - val_auc: 0.6013\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.61066\n",
      "53531/53531 - 150s - loss: 0.4731 - auc: 0.5804 - val_loss: 0.4686 - val_auc: 0.6020\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.61066\n",
      "53531/53531 - 151s - loss: 0.4643 - auc: 0.5878 - val_loss: 0.4617 - val_auc: 0.6106\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.61066 to 0.61604, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 150s - loss: 0.4581 - auc: 0.5905 - val_loss: 0.4552 - val_auc: 0.6160\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.61604 to 0.61677, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 143s - loss: 0.4514 - auc: 0.5979 - val_loss: 0.4534 - val_auc: 0.6168\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.61677 to 0.61981, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 145s - loss: 0.4447 - auc: 0.6031 - val_loss: 0.4462 - val_auc: 0.6198\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.61981\n",
      "53531/53531 - 146s - loss: 0.4408 - auc: 0.6093 - val_loss: 0.4451 - val_auc: 0.6171\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.61981 to 0.65394, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 150s - loss: 0.4335 - auc: 0.6327 - val_loss: 0.4381 - val_auc: 0.6539\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.65394 to 0.67504, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 153s - loss: 0.4262 - auc: 0.6588 - val_loss: 0.4270 - val_auc: 0.6750\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_auc improved from 0.67504 to 0.67685, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 152s - loss: 0.4212 - auc: 0.6657 - val_loss: 0.4228 - val_auc: 0.6769\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.67685\n",
      "53531/53531 - 149s - loss: 0.4168 - auc: 0.6703 - val_loss: 0.4563 - val_auc: 0.6090\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.67685 to 0.70445, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 148s - loss: 0.4150 - auc: 0.6716 - val_loss: 0.4179 - val_auc: 0.7044\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.70445\n",
      "53531/53531 - 148s - loss: 0.4224 - auc: 0.6342 - val_loss: 0.4329 - val_auc: 0.6150\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.70445\n",
      "53531/53531 - 146s - loss: 0.4211 - auc: 0.6443 - val_loss: 0.4170 - val_auc: 0.7032\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: val_auc improved from 0.70445 to 0.71357, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights.hdf5\n",
      "53531/53531 - 148s - loss: 0.4076 - auc: 0.6948 - val_loss: 0.4089 - val_auc: 0.7136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb45bfdc160>"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets run the model\n",
    "filepath=dir_path+\"best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', \n",
    "                    verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# At first we got error after 14 epochs so to complete the full 20 epochs we \n",
    "# will load the best_weights and re-run the fit part \n",
    "\n",
    "if os.path.isfile(dir_path+'best_weights.hdf5'):\n",
    "  model1.load_weights(dir_path+'best_weights.hdf5')\n",
    "\n",
    "model1.fit([X_train_schoolState,X_train_teacherPrefix,X_train_pgCategory,\n",
    "           X_train_cleanCategory,X_train_cleanSubCategory,X_train_essay,\n",
    "           np.array(dfX_train['remaining_cols'].to_list())], to_categorical(y_train), \n",
    "           epochs=7,verbose=2,batch_size=256,validation_split=0.3,\n",
    "            callbacks =callbacks_list)\n",
    "\n",
    "# Epoch 00013: val_auc did not improve from 0.76058\n",
    "# 53531/53531 - 152s - loss: 0.3956 - auc: 0.7626 - val_loss: 0.4010 - val_auc: 0.7597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YY4Ee6cJWvNK",
    "outputId": "24be95ea-b80f-4086-d1ad-513e5e9c0b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model1 : 0.762\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model1 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model1.predict([X_test_schoolState,X_test_teacherPrefix,X_test_pgCategory,\n",
    "      X_test_cleanCategory,X_test_cleanSubCategory,\n",
    "      X_test_essay,np.array(dfX_test['remaining_cols'].to_list())]),\n",
    "      average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CEOphKV6Wwwx",
    "outputId": "df4edaa6-99df-485a-8406-4438635d99f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model1 : 0.916\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model1 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model1.predict([X_test_schoolState,X_test_teacherPrefix,X_test_pgCategory,\n",
    "      X_test_cleanCategory,X_test_cleanSubCategory,\n",
    "      X_test_essay,np.array(dfX_test['remaining_cols'].to_list())]),\n",
    "      average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVIjqfDY3Gs4"
   },
   "outputs": [],
   "source": [
    "table.add_row(['Model 1',0.762,0.916])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6-Iv_cBVzDk"
   },
   "source": [
    "### 1. Go through this blog, if you have any doubt on using predefined Embedding values in Embedding layer - https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "### 2. Please go through this link https://keras.io/getting-started/functional-api-guide/ and check the 'Multi-input and multi-output models' then you will get to know how to give multiple inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AO3Te0zkVzDl"
   },
   "source": [
    "### Model-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iz9D4mnTVzDm"
   },
   "source": [
    "Use the same model as above but for 'input_seq_total_text_data' give only some words in the sentance not all the words. Filter the words as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn48lFv4VzDn"
   },
   "source": [
    "<pre>\n",
    "1. Train the TF-IDF on the Train data <br>\n",
    "2. Get the idf value for each word we have in the train data. <br>\n",
    "3. Remove the low idf value and high idf value words from our data. Do some analysis on the Idf values and based on those values choose the low and high threshold value. Because very frequent words and very very rare words don't give much information. (you can plot a box plots and take only the idf scores within IQR range and corresponding words)<br>\n",
    "4. Train the LSTM after removing the Low and High idf value words. (In model-1 Train on total data but in Model-2 train on data after removing some words based on IDF values)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wXEaHMWv_fSA",
    "outputId": "d3efcf4e-c749-4b9f-bebd-e7014234d860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<76473x24416 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8239388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfIdf_vectorizer = TfidfVectorizer(min_df=3)\n",
    "tfIdf_vectorizer.fit_transform(dfX_train.essay.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAC9gfuPIKrm"
   },
   "outputs": [],
   "source": [
    "feature_Idf_Map = dict(zip(tfIdf_vectorizer.get_feature_names(),tfIdf_vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iNUBbsPrB0yi",
    "outputId": "60d22913-d4d4-47a5-ea0e-739c4da28a10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24416"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfIdf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "VovQXbDaCFMj",
    "outputId": "4d4566e4-6cd9-476c-c5ef-658dcd75b28e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntWG7/TQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram plot of the idf values\n",
    "\n",
    "num_bins = ceil((tfIdf_vectorizer.idf_.max()-tfIdf_vectorizer.idf_.min())/0.5)\n",
    "hValues, bins, patches = plt.hist(tfIdf_vectorizer.idf_, num_bins, facecolor='blue',\n",
    "                alpha=0.5, range=(0, int(tfIdf_vectorizer.idf_.max()+1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mU17WKe5S9VM",
    "outputId": "53d2556a-2e88-4735-83ff-148c7b545f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin :  1\n",
      "Range : 0.0 - 0.55\n",
      "No of words : 0.0 which is 0.0 % of total\n",
      "Top 10 words : \n",
      "[]\n",
      "****************************************************************************************************\n",
      "Bin :  2\n",
      "Range : 0.55 - 1.1\n",
      "No of words : 2.0 which is 0.01 % of total\n",
      "Top 10 words : \n",
      "[('nannan', 1.0460394199858651), ('students', 1.0080085502013645)]\n",
      "****************************************************************************************************\n",
      "Bin :  3\n",
      "Range : 1.1 - 1.65\n",
      "No of words : 10.0 which is 0.04 % of total\n",
      "Top 10 words : \n",
      "[('many', 1.5766580863856858), ('help', 1.5164292506171393), ('they', 1.5022193040848788), ('the', 1.466500084265604), ('learn', 1.4627750651310945), ('not', 1.4507585683891664), ('classroom', 1.3946702211939477), ('learning', 1.3637010149387487), ('my', 1.244274308661387), ('school', 1.1629790147986256)]\n",
      "****************************************************************************************************\n",
      "Bin :  4\n",
      "Range : 1.65 - 2.2\n",
      "No of words : 28.0 which is 0.11 % of total\n",
      "Top 10 words : \n",
      "[('provide', 2.191979904762562), ('allow', 2.181014788688464), ('get', 2.1573149022521934), ('every', 2.1551539971560105), ('grade', 2.1145611696147935), ('reading', 2.098037095178083), ('skills', 2.075513707830516), ('want', 2.0679143357229743), ('student', 2.046312622687699), ('time', 2.0446758393448223)]\n",
      "****************************************************************************************************\n",
      "Bin :  5\n",
      "Range : 2.2 - 2.75\n",
      "No of words : 63.0 which is 0.26 % of total\n",
      "Top 10 words : \n",
      "[('around', 2.7341870570076816), ('us', 2.7271016336092417), ('better', 2.7142406598475963), ('even', 2.7113406360649677), ('level', 2.7050619736461448), ('daily', 2.691627442588886), ('experience', 2.686600349479957), ('become', 2.6858237600802015), ('know', 2.68377927419057), ('used', 2.6820904411947)]\n",
      "****************************************************************************************************\n",
      "Bin :  6\n",
      "Range : 2.75 - 3.3\n",
      "No of words : 97.0 which is 0.4 % of total\n",
      "Top 10 words : \n",
      "[('still', 3.2945623363056655), ('despite', 3.2926184492165227), ('population', 3.2921007168725738), ('some', 3.2902907616273342), ('groups', 3.282570702698326), ('two', 3.276564678638114), ('ability', 3.2571343423978814), ('everyday', 3.252024341872385), ('outside', 3.251402953671194), ('child', 3.2423743845186848)]\n",
      "****************************************************************************************************\n",
      "Bin :  7\n",
      "Range : 3.3 - 3.85\n",
      "No of words : 187.0 which is 0.77 % of total\n",
      "Top 10 words : \n",
      "[('neighborhood', 3.8467469892723885), ('curious', 3.843148244947615), ('creativity', 3.842474919818372), ('setting', 3.840457660364825), ('minds', 3.8379976345239624), ('along', 3.837104577978785), ('programs', 3.8299886929379268), ('grades', 3.829545626913842), ('critical', 3.825787470617031), ('prepare', 3.825125730215691)]\n",
      "****************************************************************************************************\n",
      "Bin :  8\n",
      "Range : 3.85 - 4.4\n",
      "No of words : 244.0 which is 1.0 % of total\n",
      "Top 10 words : \n",
      "[('highly', 4.3996816755234445), ('regular', 4.3996816755234445), ('alternative', 4.398116117473741), ('expand', 4.398116117473741), ('developing', 4.394602547589346), ('collaborate', 4.393044914875663), ('store', 4.392267007407417), ('achievement', 4.391101279667091), ('passion', 4.391101279667091), ('academics', 4.390713005540683)]\n",
      "****************************************************************************************************\n",
      "Bin :  9\n",
      "Range : 4.4 - 4.95\n",
      "No of words : 364.0 which is 1.49 % of total\n",
      "Top 10 words : \n",
      "[('excel', 4.94761508760451), ('lost', 4.94761508760451), ('weekly', 4.94626099125678), ('gets', 4.944233278497129), ('drive', 4.942209669037602), ('supports', 4.942209669037602), ('brains', 4.941536041528128), ('mini', 4.9408628674872235), ('increasing', 4.939517877371891), ('beneficial', 4.938174693825423)]\n",
      "****************************************************************************************************\n",
      "Bin :  10\n",
      "Range : 4.95 - 5.5\n",
      "No of words : 544.0 which is 2.23 % of total\n",
      "Top 10 words : \n",
      "[('chart', 5.4994697432805655), ('known', 5.4994697432805655), ('contribute', 5.498293964191554), ('barriers', 5.497119565935612), ('methods', 5.497119565935612), ('practices', 5.497119565935612), ('aware', 5.495946545273249), ('feet', 5.495946545273249), ('greatest', 5.493604623828167), ('vibrant', 5.493604623828167)]\n",
      "****************************************************************************************************\n",
      "Bin :  11\n",
      "Range : 5.5 - 6.05\n",
      "No of words : 665.0 which is 2.72 % of total\n",
      "Top 10 words : \n",
      "[('leading', 6.046227376272619), ('pen', 6.046227376272619), ('saying', 6.046227376272619), ('blue', 6.044196918722237), ('deeply', 6.044196918722237), ('represented', 6.044196918722237), ('strives', 6.044196918722237), ('demand', 6.042170575577005), ('memory', 6.040148330196238), ('sort', 6.040148330196238)]\n",
      "****************************************************************************************************\n",
      "Bin :  12\n",
      "Range : 6.05 - 6.6\n",
      "No of words : 817.0 which is 3.35 % of total\n",
      "Top 10 words : \n",
      "[('drum', 6.59925919512169), ('hallway', 6.59925919512169), ('heads', 6.59925919512169), ('jumping', 6.59925919512169), ('locations', 6.59925919512169), ('picked', 6.59925919512169), ('sleep', 6.59925919512169), ('tailored', 6.59925919512169), ('cook', 6.595731854603722), ('ended', 6.595731854603722)]\n",
      "****************************************************************************************************\n",
      "Bin :  13\n",
      "Range : 6.6 - 7.15\n",
      "No of words : 1065.0 which is 4.36 % of total\n",
      "Top 10 words : \n",
      "[('55', 7.144839664940729), ('crisis', 7.144839664940729), ('halls', 7.144839664940729), ('headsets', 7.144839664940729), ('inventions', 7.144839664940729), ('lists', 7.144839664940729), ('moreover', 7.144839664940729), ('observation', 7.144839664940729), ('pivotal', 7.144839664940729), ('rare', 7.144839664940729)]\n",
      "****************************************************************************************************\n",
      "Bin :  14\n",
      "Range : 7.15 - 7.7\n",
      "No of words : 1332.0 which is 5.46 % of total\n",
      "Top 10 words : \n",
      "[('assistive', 7.690829201164387), ('chore', 7.690829201164387), ('climbing', 7.690829201164387), ('computation', 7.690829201164387), ('contest', 7.690829201164387), ('credits', 7.690829201164387), ('delightful', 7.690829201164387), ('deodorant', 7.690829201164387), ('disc', 7.690829201164387), ('entitled', 7.690829201164387)]\n",
      "****************************************************************************************************\n",
      "Bin :  15\n",
      "Range : 7.7 - 8.25\n",
      "No of words : 1736.0 which is 7.11 % of total\n",
      "Top 10 words : \n",
      "[('3000', 8.237372907532457), ('affording', 8.237372907532457), ('apt', 8.237372907532457), ('attempts', 8.237372907532457), ('beating', 8.237372907532457), ('boat', 8.237372907532457), ('buzzers', 8.237372907532457), ('captions', 8.237372907532457), ('certificate', 8.237372907532457), ('compact', 8.237372907532457)]\n",
      "****************************************************************************************************\n",
      "Bin :  16\n",
      "Range : 8.25 - 8.8\n",
      "No of words : 1912.0 which is 7.83 % of total\n",
      "Top 10 words : \n",
      "[('2003', 8.7789701899652), ('abcs', 8.7789701899652), ('adaptation', 8.7789701899652), ('addiction', 8.7789701899652), ('affiliated', 8.7789701899652), ('astounded', 8.7789701899652), ('audiobook', 8.7789701899652), ('beakers', 8.7789701899652), ('bilingualism', 8.7789701899652), ('bind', 8.7789701899652)]\n",
      "****************************************************************************************************\n",
      "Bin :  17\n",
      "Range : 8.8 - 9.35\n",
      "No of words : 2279.0 which is 9.33 % of total\n",
      "Top 10 words : \n",
      "[('1990', 9.300267113598487), ('225', 9.300267113598487), ('aac', 9.300267113598487), ('accidental', 9.300267113598487), ('adjusts', 9.300267113598487), ('advantageous', 9.300267113598487), ('affirm', 9.300267113598487), ('alarming', 9.300267113598487), ('amelia', 9.300267113598487), ('ankle', 9.300267113598487)]\n",
      "****************************************************************************************************\n",
      "Bin :  18\n",
      "Range : 9.35 - 9.9\n",
      "No of words : 3125.0 which is 12.8 % of total\n",
      "Top 10 words : \n",
      "[('165', 9.846810819966556), ('2028', 9.846810819966556), ('215', 9.846810819966556), ('2s', 9.846810819966556), ('340', 9.846810819966556), ('3doodle', 9.846810819966556), ('4cs', 9.846810819966556), ('640', 9.846810819966556), ('90th', 9.846810819966556), ('absorbs', 9.846810819966556)]\n",
      "****************************************************************************************************\n",
      "Bin :  19\n",
      "Range : 9.9 - 10.45\n",
      "No of words : 3520.0 which is 14.42 % of total\n",
      "Top 10 words : \n",
      "[('106', 10.298795943709614), ('10s', 10.298795943709614), ('111', 10.298795943709614), ('126', 10.298795943709614), ('128', 10.298795943709614), ('148', 10.298795943709614), ('15am', 10.298795943709614), ('185', 10.298795943709614), ('190', 10.298795943709614), ('1907', 10.298795943709614)]\n",
      "****************************************************************************************************\n",
      "Bin :  20\n",
      "Range : 10.45 - 11.0\n",
      "No of words : 6426.0 which is 26.32 % of total\n",
      "Top 10 words : \n",
      "[('04', 10.858411731645036), ('08', 10.858411731645036), ('0ver', 10.858411731645036), ('109', 10.858411731645036), ('10x10', 10.858411731645036), ('116', 10.858411731645036), ('121', 10.858411731645036), ('129', 10.858411731645036), ('12pm', 10.858411731645036), ('144', 10.858411731645036)]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Lets study the distribution of words in each of the bins\n",
    "for bini in range(len(bins)-1):\n",
    "  print(\"Bin : \",bini+1)\n",
    "  print(\"Range : {} - {}\".format(round(bins[bini],3), round(bins[bini+1],3)))\n",
    "  print(\"No of words : {} which is {} % of total\".format(hValues[bini], \n",
    "          round((hValues[bini]*100)/len(tfIdf_vectorizer.get_feature_names()),2)))\n",
    "  print(\"Top 10 words : \")\n",
    "  words = sorted([(word,score) for word,score in feature_Idf_Map.items()\\\n",
    "                 if score>=bins[bini] and score<=bins[bini+1]], \n",
    "                 key=lambda x:x[1], reverse=True)[:10]\n",
    "  print(words)\n",
    "  print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOtktoifMIyK"
   },
   "outputs": [],
   "source": [
    "# we clearly see that the first 6 bins have very few words and the last bin has \n",
    "# words which are mostly digits in string format which do not add much meaning \n",
    "\n",
    "# llimit, hlimit = 3.3, 9.6\n",
    "llimit, hlimit = 2, 10\n",
    "\n",
    "def exclude_words(text):\n",
    "  return ' '.join([word for word in text.split() if \\\n",
    "                    feature_Idf_Map.get(word) is None or \n",
    "                    (feature_Idf_Map.get(word) and \\\n",
    "                  (feature_Idf_Map.get(word)>=llimit and \\\n",
    "                      feature_Idf_Map.get(word)<=hlimit))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "BW03IVkPQy63",
    "outputId": "a6df6a73-88ca-45d3-baa2-c714ae496542"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# changing the essay text to exclude the extra words\n",
    "\n",
    "dfX_train['mod_essay']=dfX_train.essay.apply(exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOVfuIBiZcl_"
   },
   "outputs": [],
   "source": [
    "dfX_test['mod_essay']=dfX_test.essay.apply(exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpSkM1kXGbeS"
   },
   "outputs": [],
   "source": [
    "dfX_cv['mod_essay']=dfX_cv.essay.apply(exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1r3J4b7EbUjP"
   },
   "outputs": [],
   "source": [
    "tokenizer_Essay2 = Tokenizer(oov_token='<oov>')\n",
    "tokenizer_Essay2.fit_on_texts(dfX_train.mod_essay.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G72y3ACObq3O"
   },
   "outputs": [],
   "source": [
    "tokenised_essay2_train = tokenizer_Essay2.texts_to_sequences(dfX_train.mod_essay)\n",
    "tokenised_essay2_cv = tokenizer_Essay2.texts_to_sequences(dfX_cv.mod_essay)\n",
    "tokenised_essay2_test = tokenizer_Essay2.texts_to_sequences(dfX_test.mod_essay)\n",
    "X_train_essay2 = pad_sequences(tokenised_essay2_train, maxlen=max_essay_length)\n",
    "X_test_essay2 = pad_sequences(tokenised_essay2_test, maxlen=max_essay_length)\n",
    "X_cv_essay2 = pad_sequences(tokenised_essay2_cv, maxlen=max_essay_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhLWA424cDos"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS = 300     # glove vectors are 300 dims\n",
    "VOCAB_SIZE = len(list(tokenizer_Essay2.word_counts.keys()))\n",
    "embedding_matrix2 = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIMS))\n",
    "for word, i in tokenizer_Essay2.word_index.items():\n",
    "    embedding_vector = glove.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix2[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQqr-kPOIzVd"
   },
   "outputs": [],
   "source": [
    "# Modified essay\n",
    "mod_essay_Inp = Input(shape=(max_essay_length,),dtype='int32',\n",
    "                  name='mod_essay_Inp')\n",
    "embedded_mod_Essay = Embedding(input_dim=len(tokenizer_Essay2.word_index.items()),\n",
    "                        output_dim=300,name='embedded_mod_Essay',\n",
    "                        weights=[embedding_matrix2],\n",
    "                        trainable=False)(mod_essay_Inp)\n",
    "mod_essay_LSTM = LSTM(units=128, return_sequences=True)(embedded_mod_Essay)\n",
    "mod_essay_Out = Flatten()(mod_essay_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MI_-us6iJp6j"
   },
   "outputs": [],
   "source": [
    "# concatenating all the outputs\n",
    "\n",
    "concatenated_Outs2 = concatenate([school_state_out, teacher_Pref_out,\n",
    "                pgCategory_Out,cleanCategory_Out,clean_subcategories_Out,\n",
    "                mod_essay_Out,remaining_cols_Out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-bUWvLBJp3M"
   },
   "outputs": [],
   "source": [
    "outPut = Dense(128,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(concatenated_Outs2)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = Dense(64,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = BatchNormalization()(outPut)\n",
    "outPut = Dense(32,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.4)(outPut)\n",
    "outPut = Dense(2, activation = 'softmax')(outPut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "cO2D1K9zJp0r",
    "outputId": "18cb75a1-0de6-4077-d177-9687c5640dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mod_essay_Inp (InputLayer)      [(None, 350)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "school_state_inp (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "teacher_Pref_inp (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pgCategory_Inp (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cleanCategory_Inp (InputLayer)  [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "clean_subcategories_Inp (InputL [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedded_mod_Essay (Embedding)  (None, 350, 300)     12005100    mod_essay_Inp[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedded_school_state (Embeddin (None, 1, 6)         312         school_state_inp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedded_teacher_Pref (Embeddin (None, 1, 2)         12          teacher_Pref_inp[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedded_pgCategory (Embedding) (None, 1, 2)         10          pgCategory_Inp[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedded_cleanCategory (Embeddi (None, 3, 3)         30          cleanCategory_Inp[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedded_cleanSubCategory (Embe (None, 3, 5)         155         clean_subcategories_Inp[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 350, 128)     219648      embedded_mod_Essay[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "remaining_cols_Inp (InputLayer) [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6)            0           embedded_school_state[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedded_teacher_Pref[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedded_pgCategory[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 9)            0           embedded_cleanCategory[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 15)           0           embedded_cleanSubCategory[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 44800)        0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           48          remaining_cols_Inp[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 44850)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          5740928     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            66          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,976,901\n",
      "Trainable params: 5,971,673\n",
      "Non-trainable params: 12,005,228\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model with all the previously defined inputs\n",
    "model2 = Model([school_state_inp,teacher_Pref_inp,pgCategory_Inp,\n",
    "                cleanCategory_Inp,clean_subcategories_Inp,mod_essay_Inp,\n",
    "                remaining_cols_Inp], outPut)\n",
    "model2.compile(loss='categorical_crossentropy', \n",
    "               optimizer=optimizers.Adam(lr=0.0006,decay = 1e-4),\n",
    "               metrics=[auc])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qY4bn1jSKWsW",
    "outputId": "b4d6e40c-6d4d-469b-ed6d-e4c6a308b3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 76473 samples, validate on 16387 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.59871, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 146s - loss: 0.7770 - auc: 0.5182 - val_loss: 0.5696 - val_auc: 0.5987\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.59871 to 0.60677, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 143s - loss: 0.5873 - auc: 0.5376 - val_loss: 0.5348 - val_auc: 0.6068\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.60677 to 0.60850, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 143s - loss: 0.5357 - auc: 0.5562 - val_loss: 0.5063 - val_auc: 0.6085\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.60850\n",
      "76473/76473 - 141s - loss: 0.5108 - auc: 0.5605 - val_loss: 0.4931 - val_auc: 0.6084\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.60850 to 0.61756, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 141s - loss: 0.4891 - auc: 0.5759 - val_loss: 0.4779 - val_auc: 0.6176\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.61756\n",
      "76473/76473 - 139s - loss: 0.4749 - auc: 0.5861 - val_loss: 0.4725 - val_auc: 0.6073\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.61756 to 0.65281, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 140s - loss: 0.4650 - auc: 0.5957 - val_loss: 0.4491 - val_auc: 0.6528\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.65281\n",
      "76473/76473 - 139s - loss: 0.4577 - auc: 0.5887 - val_loss: 0.4431 - val_auc: 0.6522\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.65281 to 0.68000, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 140s - loss: 0.4438 - auc: 0.6382 - val_loss: 0.4328 - val_auc: 0.6800\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.68000 to 0.69455, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 140s - loss: 0.4370 - auc: 0.6380 - val_loss: 0.4252 - val_auc: 0.6945\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.69455 to 0.69838, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 140s - loss: 0.4231 - auc: 0.6822 - val_loss: 0.4187 - val_auc: 0.6984\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.69838 to 0.69954, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 139s - loss: 0.4207 - auc: 0.6826 - val_loss: 0.4164 - val_auc: 0.6995\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.69954 to 0.71383, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 138s - loss: 0.4117 - auc: 0.6993 - val_loss: 0.4082 - val_auc: 0.7138\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.71383 to 0.72182, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 139s - loss: 0.4035 - auc: 0.7158 - val_loss: 0.4032 - val_auc: 0.7218\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.72182\n",
      "76473/76473 - 137s - loss: 0.3971 - auc: 0.7273 - val_loss: 0.4019 - val_auc: 0.7211\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.72182 to 0.72828, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights2.hdf5\n",
      "76473/76473 - 138s - loss: 0.3892 - auc: 0.7421 - val_loss: 0.4067 - val_auc: 0.7283\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.72828\n",
      "76473/76473 - 137s - loss: 0.3824 - auc: 0.7537 - val_loss: 0.3956 - val_auc: 0.7207\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.72828\n",
      "76473/76473 - 137s - loss: 0.3761 - auc: 0.7647 - val_loss: 0.4018 - val_auc: 0.7276\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.72828\n",
      "76473/76473 - 136s - loss: 0.3717 - auc: 0.7730 - val_loss: 0.3956 - val_auc: 0.7233\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.72828\n",
      "76473/76473 - 136s - loss: 0.3642 - auc: 0.7845 - val_loss: 0.3968 - val_auc: 0.7233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f134b3b2fd0>"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets run the model\n",
    "filepath=dir_path+\"best_weights2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', \n",
    "                    verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "if os.path.isfile(dir_path+'best_weights2.hdf5'):\n",
    "  model2.load_weights(dir_path+'best_weights2.hdf5')\n",
    "\n",
    "model2.fit([X_train_schoolState,X_train_teacherPrefix,X_train_pgCategory,\n",
    "           X_train_cleanCategory,X_train_cleanSubCategory,X_train_essay2,\n",
    "           np.array(dfX_train['remaining_cols'].to_list())], to_categorical(y_train), \n",
    "           epochs=20,verbose=2,batch_size=256,validation_data=([X_cv_schoolState,\n",
    "           X_cv_teacherPrefix,X_cv_pgCategory,X_cv_cleanCategory,\n",
    "           X_cv_cleanSubCategory,X_cv_essay2,np.array(dfX_cv['remaining_cols'].to_list())]\n",
    "           ,to_categorical(y_cv)),\n",
    "           callbacks =callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wwRFFxGtU1i_",
    "outputId": "d648d0f4-8c88-4d1c-dc66-445fb7af2207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model2 : 0.718\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model2 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model2.predict([X_test_schoolState,X_test_teacherPrefix,X_test_pgCategory,\n",
    "      X_test_cleanCategory,X_test_cleanSubCategory,\n",
    "      X_test_essay2,np.array(dfX_test['remaining_cols'].to_list())]),\n",
    "      average='weighted'))\n",
    "\n",
    "      # Last 0.683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qXS_tTwGU4Mc",
    "outputId": "1ea00220-458e-43ae-ab4c-8cb7fff544a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model2 : 0.905\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model2 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model2.predict([X_test_schoolState,X_test_teacherPrefix,X_test_pgCategory,\n",
    "      X_test_cleanCategory,X_test_cleanSubCategory,\n",
    "      X_test_essay2,np.array(dfX_test['remaining_cols'].to_list())]), \n",
    "      average='micro'))\n",
    "\n",
    "# 0.876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jKNGweM3Xrb"
   },
   "outputs": [],
   "source": [
    "table.add_row(['Model 2',0.718,0.905])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CY5pkvFDVzDo"
   },
   "source": [
    "### Model-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adN4cJy3VzDp"
   },
   "source": [
    "<img src='https://i.imgur.com/fkQ8nGo.png'>\n",
    "ref: https://i.imgur.com/fkQ8nGo.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_jHjwgJVzDq"
   },
   "source": [
    "\n",
    "- __input_seq_total_text_data__: <br>\n",
    "<pre>\n",
    "    . Use text column('essay'), and use the Embedding layer to get word vectors. <br>\n",
    "    . Use given predefined glove word vectors, don't train any word vectors. <br>\n",
    "    . Use LSTM that is given above, get the LSTM output and Flatten that output. <br>\n",
    "    . You are free to preprocess the input text as you needed. <br>\n",
    "</pre>\n",
    "- __Other_than_text_data__:<br>\n",
    "<pre>\n",
    "    . Convert all your Categorical values to onehot coded and then concatenate all these onehot vectors <br>\n",
    "    . Neumerical values and use <a href='https://keras.io/getting-started/sequential-model-guide/#sequence-classification-with-1d-convolutions'>CNN1D</a> as shown in above figure. <br>\n",
    "    . You are free to choose all CNN parameters like kernel sizes, stride.<br>\n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wKLJqjmVbphY",
    "outputId": "ba6999d8-ed8f-40e5-c479-5c6a5677c4e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the 'Essay' layer from the Model1\n",
    "# Lets work on the all other columns\n",
    "\n",
    "mlbinarizer_schoolState = MultiLabelBinarizer()\n",
    "mlbinarizer_schoolState.fit([dfX_train.school_state.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "shVTcsTTcB9d"
   },
   "outputs": [],
   "source": [
    "X_train_schoolState = mlbinarizer_schoolState.transform(\\\n",
    "                        dfX_train.school_state.apply(lambda x : [x]))\n",
    "X_test_schoolState = mlbinarizer_schoolState.transform(\\\n",
    "                        dfX_test.school_state.apply(lambda x : [x]))\n",
    "X_cv_schoolState = mlbinarizer_schoolState.transform(\\\n",
    "                        dfX_cv.school_state.apply(lambda x : [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CdMQsDMjgq7c",
    "outputId": "1f93ef95-b497-4da0-be47-e38bcf323a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76473, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_schoolState.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wviF1ZJkei5Z"
   },
   "outputs": [],
   "source": [
    "mlbinarizer_teacherPrefix = MultiLabelBinarizer()\n",
    "mlbinarizer_teacherPrefix.fit([dfX_train.teacher_prefix.to_list()])\n",
    "\n",
    "X_train_teacherPrefix = mlbinarizer_teacherPrefix.transform(\\\n",
    "                      dfX_train.teacher_prefix.apply(lambda x : [x]))\n",
    "X_test_teacherPrefix = mlbinarizer_teacherPrefix.transform(\\\n",
    "                      dfX_test.teacher_prefix.apply(lambda x : [x]))\n",
    "X_cv_teacherPrefix = mlbinarizer_teacherPrefix.transform(\\\n",
    "                      dfX_cv.teacher_prefix.apply(lambda x : [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3zQGF0asgv5S",
    "outputId": "65f14538-4f92-48d0-b870-28e73e87407c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76473, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_teacherPrefix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbY-2bsMcDBE"
   },
   "outputs": [],
   "source": [
    "mlbinarizer_pgCategory = MultiLabelBinarizer()\n",
    "mlbinarizer_pgCategory.fit([dfX_train.project_grade_category.to_list()])\n",
    "\n",
    "X_train_pgCategory = mlbinarizer_pgCategory.transform(\\\n",
    "                      dfX_train.project_grade_category.apply(lambda x : [x]))\n",
    "X_test_pgCategory = mlbinarizer_pgCategory.transform(\\\n",
    "                      dfX_test.project_grade_category.apply(lambda x : [x]))\n",
    "X_cv_pgCategory = mlbinarizer_pgCategory.transform(\\\n",
    "                      dfX_cv.project_grade_category.apply(lambda x : [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jd-RJwDGg0HW",
    "outputId": "4ed446b0-84d9-4b3e-e812-eb5df653a2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76473, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pgCategory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3H3hIDFfQs0"
   },
   "outputs": [],
   "source": [
    "mlbinarizer_cleanCategory = MultiLabelBinarizer()\n",
    "mlbinarizer_cleanCategory.fit([dfX_train.clean_categories.to_list()])\n",
    "\n",
    "X_train_cleanCategory = mlbinarizer_cleanCategory.transform(\\\n",
    "                      dfX_train.clean_categories.apply(lambda x : [x]))\n",
    "X_test_cleanCategory = mlbinarizer_cleanCategory.transform(\\\n",
    "                      dfX_test.clean_categories.apply(lambda x : [x]))\n",
    "X_cv_cleanCategory = mlbinarizer_cleanCategory.transform(\\\n",
    "                      dfX_cv.clean_categories.apply(lambda x : [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yfeFlsL0g3tO",
    "outputId": "4207514e-9317-4843-d536-1b3c3e290c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76473, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cleanCategory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "QKFG088cfQfn",
    "outputId": "3df831d1-1bc5-4342-b307-8930474011f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:951: UserWarning: unknown class(es) ['civics_government parentinvolvement', 'civics_government teamsports', 'earlydevelopment history_geography', 'economics foreignlanguages', 'financialliteracy health_lifescience', 'socialsciences teamsports'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:951: UserWarning: unknown class(es) ['civics_government teamsports', 'economics music', 'economics other', 'financialliteracy health_lifescience', 'financialliteracy health_wellness', 'socialsciences teamsports'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    }
   ],
   "source": [
    "mlbinarizer_cleanSubCategory = MultiLabelBinarizer()\n",
    "mlbinarizer_cleanSubCategory.fit([dfX_train.clean_subcategories.to_list()])\n",
    "\n",
    "X_train_cleanSubCategory = mlbinarizer_cleanSubCategory.transform(\\\n",
    "                      dfX_train.clean_subcategories.apply(lambda x : [x]))\n",
    "X_test_cleanSubCategory = mlbinarizer_cleanSubCategory.transform(\\\n",
    "                      dfX_test.clean_subcategories.apply(lambda x : [x]))\n",
    "X_cv_cleanSubCategory = mlbinarizer_cleanSubCategory.transform(\\\n",
    "                      dfX_cv.clean_subcategories.apply(lambda x : [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aWDxBCNIg7-x",
    "outputId": "d1dc3755-326c-418c-ad9c-d24a74cccc1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76473, 392)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cleanSubCategory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqtgLAu6gZNO"
   },
   "outputs": [],
   "source": [
    "X_train_concat = np.hstack((X_train_schoolState,X_train_teacherPrefix,X_train_pgCategory,\n",
    "          X_train_cleanCategory,X_train_cleanSubCategory))\n",
    "X_test_concat = np.hstack((X_test_schoolState,X_test_teacherPrefix,X_test_pgCategory,\n",
    "          X_test_cleanCategory,X_test_cleanSubCategory))\n",
    "X_cv_concat = np.hstack((X_cv_schoolState,X_cv_teacherPrefix,X_cv_pgCategory,\n",
    "          X_cv_cleanCategory,X_cv_cleanSubCategory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gw-5wblN2eY1"
   },
   "outputs": [],
   "source": [
    "X_train_concat=np.expand_dims(X_train_concat, axis=2)\n",
    "X_test_concat=np.expand_dims(X_test_concat, axis=2)\n",
    "X_cv_concat=np.expand_dims(X_cv_concat, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OVwh71xxm9E_",
    "outputId": "5cc16335-c375-480c-c217-fb00e2990f55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76473, 503, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1RTyuMJwTIn"
   },
   "outputs": [],
   "source": [
    "dims = X_train_concat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhnboWEXgZJO"
   },
   "outputs": [],
   "source": [
    "stacked_Inp = Input(shape=(dims,1), name='stacked_Inp')\n",
    "conv_out = Conv1D(128, kernel_size=(3),activation='relu')(stacked_Inp)  #128\n",
    "conv_out = Conv1D(64, kernel_size=(2),activation='relu')(conv_out)  # 64\n",
    "# conv_out = Conv1D(32, kernel_size=(2),activation='relu')(conv_out)    Ommiting\n",
    "#                 this layer\n",
    "conv_out = Flatten()(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNt81qZCzLlW"
   },
   "outputs": [],
   "source": [
    "concatenated_Outs3=concatenate([essay_Out, conv_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bU7zY9_VgZHP"
   },
   "outputs": [],
   "source": [
    "# We are using the same configuration as the model1\n",
    "\n",
    "outPut = Dense(256,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(concatenated_Outs3)\n",
    "outPut = Dropout(0.5)(outPut)\n",
    "outPut = Dense(64,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.5)(outPut)\n",
    "outPut = BatchNormalization()(outPut)\n",
    "outPut = Dense(32,activation='relu',\n",
    "               kernel_initializer=initializers.he_normal(),\n",
    "               kernel_regularizer=regularizers.l2(0.001))(outPut)\n",
    "outPut = Dropout(0.5)(outPut)\n",
    "outPut = Dense(2, activation = 'softmax')(outPut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "colab_type": "code",
    "id": "-fdrZhMngZDW",
    "outputId": "afdf0ace-d9e0-4b36-fb0a-7277f5cc6421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "essay_Inp (InputLayer)          [(None, 350)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stacked_Inp (InputLayer)        [(None, 503, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedded_Essay (Embedding)      (None, 350, 300)     14799000    essay_Inp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 501, 128)     512         stacked_Inp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 350, 128)     219648      embedded_Essay[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 64)      16448       conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 44800)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 32000)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 76800)        0           flatten_5[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          19661056    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           16448       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 32)           2080        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            66          dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,715,514\n",
      "Trainable params: 19,916,386\n",
      "Non-trainable params: 14,799,128\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create model with all the previously defined inputs\n",
    "model3 = Model([essay_Inp, stacked_Inp], outPut)\n",
    "model3.compile(loss='categorical_crossentropy', \n",
    "               optimizer=optimizers.Adam(lr=0.0006,decay = 1e-4),\n",
    "               metrics=[auc])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jFXE7gVUS1g7",
    "outputId": "eefe1d2c-c80f-4172-c965-92bafa11497e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16387, 350)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv_essay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "offcTbhfcB6C",
    "outputId": "5a04d5da-5ab0-48c5-d147-da8e88f5c115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76473 samples, validate on 16387 samples\n",
      "Epoch 1/5\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.71909, saving model to /content/drive/My Drive/Colab Notebooks/AppliedAI/LSTM_Donors_Choose/best_weights3.hdf5\n",
      "76473/76473 - 146s - loss: 0.4252 - auc: 0.7538 - val_loss: 0.4245 - val_auc: 0.7191\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 00002: val_auc did not improve from 0.71909\n",
      "76473/76473 - 141s - loss: 0.4152 - auc: 0.7684 - val_loss: 0.4411 - val_auc: 0.7156\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.71909\n",
      "76473/76473 - 140s - loss: 0.4072 - auc: 0.7891 - val_loss: 0.4382 - val_auc: 0.7171\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 00004: val_auc did not improve from 0.71909\n",
      "76473/76473 - 139s - loss: 0.3995 - auc: 0.8046 - val_loss: 0.4441 - val_auc: 0.7080\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.71909\n",
      "76473/76473 - 139s - loss: 0.3859 - auc: 0.8274 - val_loss: 0.4676 - val_auc: 0.7025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb4efee748>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets run the model\n",
    "filepath=dir_path+\"best_weights3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', \n",
    "                    verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "if os.path.isfile(dir_path+'best_weights3.hdf5'):\n",
    "  model3.load_weights(dir_path+'best_weights3.hdf5')\n",
    "\n",
    "model3.fit([X_train_essay, X_train_concat], to_categorical(y_train), \n",
    "           epochs=5,verbose=2,batch_size=256,\n",
    "           validation_data=([X_cv_essay,X_cv_concat],to_categorical(y_cv)),\n",
    "           callbacks =callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Yag7_KHjcJDm",
    "outputId": "1690b191-c1df-427e-e225-2678076f5b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model3 : 0.707\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model3 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model3.predict([X_test_essay, X_test_concat]),\n",
    "      average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nj-0G2utmtah",
    "outputId": "d5462131-80ed-4e87-99c8-4613e9cd3e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for Model3 : 0.902\n"
     ]
    }
   ],
   "source": [
    "# AUC for test data\n",
    "print(\"Test AUC for Model3 : %0.3f\"%roc_auc_score(to_categorical(y_test),\n",
    "      model3.predict([X_test_essay, X_test_concat]), \n",
    "      average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6wOw3893fTE"
   },
   "outputs": [],
   "source": [
    "table.add_row(['Model 3',0.707,0.902])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "ukViSoA63mKU",
    "outputId": "0c79e4f7-ce26-46b7-8ba3-9d9c0e7da69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+----------------+\n",
      "|  Model  | Weighted Test AUC | Micro Test AUC |\n",
      "+---------+-------------------+----------------+\n",
      "| Model 1 |       0.762       |     0.916      |\n",
      "| Model 2 |       0.718       |     0.905      |\n",
      "| Model 3 |       0.707       |     0.902      |\n",
      "+---------+-------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIeSEXGA3npW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "G6-Iv_cBVzDk"
   ],
   "name": "LSTM - Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
